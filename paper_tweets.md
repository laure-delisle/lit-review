# Tweets about papers I read

## Text2Live
Text-driven image/video editing by @omerbartal et al. Zero-shot using ONE captioned image + pre-trained CLIP model to generate an edit layer. Foreground/background texture edits.
ðŸ“‘paper: https://arxiv.org/abs/2204.02491 https://pic.twitter.com/VowYdgbA4V
[[https://github.com/laure-delisle/lit-review/blob/master/img/tweets/text2live_loss.jpeg|alt=Text2Live loss breakdown]]